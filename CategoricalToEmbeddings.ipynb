{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CategoricalToEmbeddings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJm3otlIGTTwrOSu270iM9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH98AXEQp6yW",
        "colab_type": "code",
        "outputId": "465bf3db-ebb2-47f6-9e2a-52c5c3e3d665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential,Model\n",
        "from keras.models import Model as KerasModel\n",
        "from keras.layers import Input, Dense, Activation, Reshape\n",
        "from keras.layers import Concatenate, Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "emotionsList= ['like','antipathy', 'hostility','love','warmth','loathe','abhor','intimacy','dislike','venom','affection',\n",
        "               'tenderness','animosity','attachment','infatuation','fondness','hate'] \n",
        "\n",
        "#One hot encode the above list\n",
        "ohe = OneHotEncoder()\n",
        "X = np.array(emotionsList, dtype=object).reshape(-1, 1)\n",
        "transformed_X =ohe.fit_transform(X).toarray()\n",
        "transformed_X #onehot sparse array of shape (17,17) is the result\n",
        "#As you can see Transformation of categorical variable(s) in to onehot results in very high dimensions."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "        0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RIKn2pVtHgo",
        "colab_type": "code",
        "outputId": "375d6847-7296-4814-e1ea-dc59502aa966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "#To get repeatable results OR To get stable results use seed as below. In this case we get same set of weights/embedings in every run\n",
        "# If we omit below 4 lines at each run, different weights/embedings are produced.\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\n",
        "\n",
        "#Define Embedding Size               \n",
        "embedding_size = int(min(np.ceil((len(emotionsList))/2), 50 ))\n",
        "\n",
        "emotion_index = {emotion: idx for idx, emotion in enumerate(emotionsList)}\n",
        "index_emotion = {idx: emotion for emotion, idx in emotion_index.items()}\n",
        "\n",
        "#Converting the categorical input to an enity embedding using Neural network embedding layer to reduce the dimenstions from 17 to 9\n",
        "input_model = Input(shape=(1,))\n",
        "output_model = Embedding(len(emotionsList), embedding_size, name='emotions_embedding')(input_model) \n",
        "output_model = Reshape(target_shape=(embedding_size,))(output_model)\n",
        "\n",
        "model = Model(inputs = input_model, outputs = output_model)\n",
        "model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Here Weights are the embeddings,so retreving the weights generated \n",
        "emotions_layer = model.get_layer('emotions_embedding')\n",
        "emotions_weights = emotions_layer.get_weights()[0]\n",
        "print(emotions_weights) # embedding vector of (17,9)\n",
        "\n",
        "#As you can see below each emotion from emotionsList is transformed in to an embedding weight/vector of size 9 as opposed to 17 with onehot"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.74238326e-02 -1.01963505e-02  3.13716270e-02 -1.64878368e-03\n",
            "  -1.10065229e-02  1.29030831e-02 -3.10807824e-02  1.21418461e-02\n",
            "  -4.18641567e-02]\n",
            " [-9.48626921e-03  4.05936278e-02  4.72326763e-02 -4.25748602e-02\n",
            "   1.62261724e-03 -3.12898532e-02 -2.86918283e-02 -2.45502237e-02\n",
            "   1.62344053e-03]\n",
            " [-3.08156013e-04 -2.55837794e-02 -3.85068282e-02 -3.10104378e-02\n",
            "   2.75073536e-02  2.66973712e-02 -6.30190223e-03  2.11631171e-02\n",
            "   2.75010988e-03]\n",
            " [-1.50858387e-02  3.67283709e-02  3.98593210e-02  2.54743434e-02\n",
            "   2.34374292e-02 -3.30721140e-02 -1.88026782e-02  5.64099476e-03\n",
            "  -1.90675259e-02]\n",
            " [ 8.03954899e-05 -4.13990393e-02 -2.62950789e-02 -9.32812691e-05\n",
            "   6.46386296e-03  7.42943212e-03 -2.41417885e-02  2.87023522e-02\n",
            "  -2.55922228e-03]\n",
            " [ 2.11567171e-02 -2.89756786e-02  2.26801969e-02  4.37210873e-03\n",
            "  -5.30521944e-03 -2.24559195e-02  7.60009140e-03  9.04453918e-03\n",
            "   2.80689634e-02]\n",
            " [-4.53131199e-02 -7.19735771e-03  1.36564709e-02  4.30800356e-02\n",
            "  -3.56816277e-02 -3.49362493e-02  9.73546505e-03 -6.26396388e-04\n",
            "   2.39886679e-02]\n",
            " [ 3.35456058e-03 -7.32959434e-03 -1.75563805e-02 -2.99311038e-02\n",
            "  -4.13746126e-02 -1.62804238e-02 -1.78279281e-02 -6.92162663e-03\n",
            "   1.75289065e-03]\n",
            " [ 2.63564028e-02  3.65486033e-02  4.31872532e-03 -4.21147421e-03\n",
            "   2.66884677e-02 -7.12318346e-03  3.10217403e-02 -8.58925283e-04\n",
            "  -2.02247147e-02]\n",
            " [-1.49960518e-02  3.99212949e-02  3.15110572e-02 -4.69258428e-02\n",
            "   1.23209879e-03  3.02814320e-03 -4.61426266e-02  1.61158480e-02\n",
            "   4.71824296e-02]\n",
            " [-2.18006726e-02  4.61029671e-02  1.41041912e-02 -2.53853090e-02\n",
            "  -7.50180334e-03 -4.45409790e-02 -1.94643624e-02 -3.64348292e-02\n",
            "   4.18665893e-02]\n",
            " [ 5.49471378e-03 -3.87295112e-02  3.34910303e-03  2.41174214e-02\n",
            "  -3.56346145e-02 -4.54400666e-02  4.54692952e-02 -1.22577064e-02\n",
            "   4.04070504e-02]\n",
            " [ 3.90527956e-02 -4.64838147e-02 -4.14010510e-02  3.63695882e-02\n",
            "  -1.47944316e-02  7.33364373e-04  2.40710638e-02  2.90937312e-02\n",
            "  -4.89020236e-02]\n",
            " [-3.57763842e-03 -9.64657217e-03 -4.94723804e-02 -3.16942930e-02\n",
            "   2.71127112e-02  2.55674385e-02  2.90806219e-03  2.90638208e-03\n",
            "   4.12307270e-02]\n",
            " [ 1.58673860e-02 -2.69270074e-02  4.48011495e-02 -3.35495695e-02\n",
            "  -1.80866607e-02  4.08599414e-02  4.36771773e-02 -3.03148385e-02\n",
            "  -9.12717730e-03]\n",
            " [-5.16880676e-03  1.95713751e-02  1.03336573e-03  2.16097720e-02\n",
            "   5.30421734e-03  1.85480379e-02  4.36445959e-02  3.99339311e-02\n",
            "   4.22949828e-02]\n",
            " [-2.92947050e-02 -3.67974117e-03 -3.48102674e-02  2.49300040e-02\n",
            "  -2.72727851e-02 -6.30825758e-03  1.84430592e-02  2.03898586e-02\n",
            "   2.72773542e-02]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}